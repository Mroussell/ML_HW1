{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Homework 1 and 2\n",
    "\n",
    "Michael Roussell\n",
    "\n",
    "GSU CSC 4370\n",
    "\n",
    "Fall 2021\n",
    "\n",
    "---------------------------------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1\n",
    "\n",
    "Supervised learning in machine learning is the task of having a machine learn given practice input and output. \n",
    "It is usually given by the standard mapping function Y = f(x). \n",
    "Unsupervized learning is machine learning is the task of having a machine learn given only input. \n",
    "In other words there is only a given x in the Y = f(x) function. \n",
    "A common difficulty with unsupervised learning is that labels and context are not given to the algorithm so it is left on its own to find an output structure. \n",
    "\n",
    "Some supervised learning algorithms are linear regression, random forest classification, and neural networking.\n",
    "Some unsupervised learning algorithms are k-mean clustering, q-learning, and temporal difference."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2\n",
    "\n",
    "A parametric method is one that has a set of parameters used in the determination of models in machine learning involving probabilities. \n",
    "They have a limit of fit quality base on disturabution.\n",
    "A non-parametric method is one where no set of assumed parameter is used in which the methods do not directly depend on the population being studied. \n",
    "THey keep imporoving as more data is added.\n",
    "\n",
    "Parametric methods assume a normal distrubution, so when there is one and the parameters and population affect the output it can be very useful.\n",
    "However since it assumes normal distrubution, if this is not the case it can also yield unwanted results.\n",
    "Non-parametric methods are usually considered faster when it comes to computational speed.\n",
    "This means that many paramentric methods are slower.\n",
    "Both parametrics and non-parametric methods perform with well spread groups in data.\n",
    "Parametrics methods can be easily affected by outliers, while non-parametric methods are not affected by outliers. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3\n",
    "\n",
    "Standard error is defined by the formula SE = (sigma / squareroot(n)), where signma = the sample standard deviation and n = the number of samples.\n",
    "The stanadard error measures the accuracy of which a sample distrabution represents a population.\n",
    "\n",
    "Co-variance is defined by the sum of the difference of a data point against its means value, multiplied by another data point difference against its mean, and all over the total number of data values.\n",
    "It is mainly used to measure how much two variables vary together. \n",
    "\n",
    "Co-relation is defined as the relation that two variables have together, whether via causation or not. \n",
    "It is used to track how much one data point and another relate or depend on the other. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 4\n",
    "\n",
    "The basic idea is to find a best fit line to represent our data. \n",
    "This is represented by the equation Y(pred) = b_0 + b_1 X.\n",
    "The Null Hypothesis then is used to test using prior research and knowledge, the Low P-Value then shows for if the predictor features indicates the target value, and the High P-value then shows for if the non-predictor features are not indicators of the target value."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 5\n",
    "\n",
    "Y_hat = b_0 + b_1 * X_1 + b_2 * X_2 ... b_n * X_n\n",
    "\n",
    "Where Y_hat is the target/predicted/expected value, X_1 to X_n are the predictor/independent variables, b_0 is te value of Y_hat when all Xs are either zero or do not exist, and b_1 to b_n are regressiong coefficients. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 6\n",
    "\n",
    "Principle Component Analysis or PCA is an algorithm used in unsupervised learning. \n",
    "PCA can be used for the cases of visualizing multi dimential data, simplifying decesions, compressing data, de-noising, and reducing the number of dimensions in data.\n",
    "PCA usually works by completing several steps of data manipulation.\n",
    "Firstly, the data must be standardized. \n",
    "Then, a covriance matrix is computed into a square matrix.\n",
    "Next, using eigendecomposition, the eigenvectors are sorted.\n",
    "From here the number of principle components are decided by usually observing the cumulative shared variance. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 7\n",
    "\n",
    "Standardization or Normalization are pre-processing steps that can be used in PCA. \n",
    "These methods do not always yield the same result.\n",
    "\n",
    "    MORE TODO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 8\n",
    "\n",
    "Clustering in Machine Learning is an unsupervised task that involves recognizing 'natural' groups in data sets.\n",
    "It involves only taking input data and then using the features to identify gorupings.\n",
    "\n",
    "K-Means Clustering Algorithm:\n",
    "\n",
    "    1. Let K be some integer value, k be some integer, and S be a data set of features.\n",
    "\n",
    "    2. Shuffle the data in S and randomly select K data points as a set of centriods, C.\n",
    "\n",
    "    3. For each c in C:\n",
    "\n",
    "        1. Update c by assigning closest k to c.\n",
    "\n",
    "    4. If C contains any changes from the previous interation to the next, repeate step 3.\n",
    "\n",
    "    5. IF C contains no chagnes from the previous interation, End.\n",
    "    \n",
    "\n",
    "Essientually, it partitions a set of observations into a number of clusters k, that results in the data being partitioned."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 9\n",
    "\n",
    "Generally clustering is considered to be advantageous for a few reasons.\n",
    "Clustering scales for large data, allows results in convergence and easily adapts to new sample data.\n",
    "It is also fairly simple to implement in comparison to other solutions.\n",
    "Some common dissadvantages to clustering are having to manually choose k and thus having to know information about how to choose k ahead of time, introducing outliers, and scaling based on a large amount of features or dimensions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 10\n",
    "\n",
    "K-mean is used when there are a specific number of clusters known, and thus k-means requires prior information about.\n",
    "Hierarchical clustering is used when the number of clusters is unknown and the desired outcome to is cluster data in a hierarchy of clusters.\n",
    "An example of a structure that k-means works well on is 2D circle of 3D sphere clusters.\n",
    "Hierarchical clustering does not work as well on this type of clustering.\n",
    "However, hierarchical clustering can be used when looking a graphs such as social networks or trees. \n",
    "Nodes can be compared to eachother to create groups of seperation such that similar nodes are grouped and clustered."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 11\n",
    "\n",
    "Here we will use pandas, numpy, and sklearn to computer all of the learning algorithms in some python."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PCA Calculation and Visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"Gather initial data set and exclude none number features\"\"\"\n",
    "import pandas\n",
    "\n",
    "df = pandas.read_csv(r'kmeans_dataset.csv')\n",
    "df.drop(columns=['Country or region'], inplace=True)\n",
    "features = df.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"Standardize dataset\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separating out the features\n",
    "x = df.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = df.loc[:,['Score']].values\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"Find principal components\"\"\"\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pandas.DataFrame(data=principalComponents, columns=['principal component 1', 'principal component 2'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"Create final DataFrame and Visualize it\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "finalDf = pandas.concat([principalDf, df[['Score']]], axis = 1)\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['Score'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 12\n",
    "\n",
    "### a)\n",
    "\n",
    "The equation for linear regression goes as follows:\n",
    "\n",
    "Y = b_0 + b_1 X, where Y is the dependent variable, X is the independent variable, b_0 is the intercept, and b_1 is the slope.\n",
    "\n",
    "b_0 = Y_mean - b_1 X_mean\n",
    "\n",
    "b_1 = (∑(x_i - x_mean)(y_i - y_mean))/(∑(x_i - x_mean)^2)\n",
    "\n",
    "b_1 is defined as the co-variance devided by the measure of center and spread or MSE(Mean Squared Error).\n",
    "\n",
    "### b)\n",
    "\n",
    "The MSE is the defualt loss function.\n",
    "R^2 is \n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Plot for part (c)\"\"\"\n",
    "x = [6, 3, 6, 9, 3, 9, 6, 3, 9, 6, 3, 9]\n",
    "y = [526, 421, 581, 630, 412, 560, 434, 443, 590, 570, 346, 672] \n",
    "plt.plot(x, y, 'o', color ='red') "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13ea0adf0>]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}